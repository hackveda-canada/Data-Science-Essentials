{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science Essentials Day 11, 12, & 13: N-grams, Bag of Words, Term-Document Matrix, & TF*IDF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hackveda-canada/Data-Science-Essentials/blob/master/Data_Science_Essentials_Day_11%2C_12%2C_%26_13_N_grams%2C_Bag_of_Words%2C_Term_Document_Matrix%2C_%26_TF_IDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YSgQNAc7rZqW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Day 11**\n",
        "----------------\n",
        "\n",
        "#**N-GRAMS**\n",
        "----------------\n",
        "\n",
        "\n",
        "an n-gram is continous sequence of n items from a given sample of text or speech.\n",
        "\n",
        "We will be using nltk Python library, and collections library to use Counter function"
      ]
    },
    {
      "metadata": {
        "id": "ShLNQcgRsNVo",
        "colab_type": "code",
        "outputId": "ca9af638-49f2-47ca-a2fa-aceeb771a4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "cell_type": "code",
      "source": [
        "# Concepts of N-grams in Text Analytics\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "\n",
        "text = \"Welcome to Machine Learning\"\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def get_ngrams(text, n):\n",
        "  tokens = word_tokenize(text)\n",
        "  print(tokens)\n",
        "  n_grams = ngrams(tokens, n)\n",
        "  return [\" \".join(gram) for gram in n_grams]\n",
        "  \n",
        " \n",
        "  \n",
        "  \n",
        "print(\"Unigram (n=1)\",get_ngrams(text, 1))\n",
        "print(\"Bigram (n=2)\",get_ngrams(text, 2))\n",
        "print(\"Trigram (n=3)\",get_ngrams(text, 3))\n",
        "print(\"Quadgram (n=4)\",get_ngrams(text, 4))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['Welcome', 'to', 'Machine', 'Learning']\n",
            "Unigram (n=1) ['Welcome', 'to', 'Machine', 'Learning']\n",
            "['Welcome', 'to', 'Machine', 'Learning']\n",
            "Bigram (n=2) ['Welcome to', 'to Machine', 'Machine Learning']\n",
            "['Welcome', 'to', 'Machine', 'Learning']\n",
            "Trigram (n=3) ['Welcome to Machine', 'to Machine Learning']\n",
            "['Welcome', 'to', 'Machine', 'Learning']\n",
            "Quadgram (n=4) ['Welcome to Machine Learning']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W_RM-bLS1GkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Extract n-grams from text and create a table repersenting n-grams and its frequency"
      ]
    },
    {
      "metadata": {
        "id": "690nZdJR1S7U",
        "colab_type": "code",
        "outputId": "cd852829-53dc-4432-a927-53cc16c0b864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "text = \"Statistics skills, and programming skills are equally important for analytics. Statistics skills, and domain knowledge are important for analytics\"\n",
        "\n",
        "# Remove noise = punctuation marks (string.punctuation)\n",
        "\n",
        "import string\n",
        "\n",
        "# Define a function remove the punctuation\n",
        "def remove_punctuation(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  nf_text = [token for token in tokens if token.lower() not in string.punctuation]\n",
        "  return \" \".join(nf_text)\n",
        "\n",
        "\n",
        "print(remove_punctuation(text))\n",
        "\n",
        "text = remove_punctuation(text)\n",
        "\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics skills and programming skills are equally important for analytics Statistics skills and domain knowledge are important for analytics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UwSiDNz04JvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Extract n-grams**"
      ]
    },
    {
      "metadata": {
        "id": "tageTcQD4N0z",
        "colab_type": "code",
        "outputId": "a6cf40c1-765f-4c98-9854-c48d3d996ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "result = get_ngrams(text, 2)\n",
        "print(result)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Statistics', 'skills', 'and', 'programming', 'skills', 'are', 'equally', 'important', 'for', 'analytics', 'Statistics', 'skills', 'and', 'domain', 'knowledge', 'are', 'important', 'for', 'analytics']\n",
            "['Statistics skills', 'skills and', 'and programming', 'programming skills', 'skills are', 'are equally', 'equally important', 'important for', 'for analytics', 'analytics Statistics', 'Statistics skills', 'skills and', 'and domain', 'domain knowledge', 'knowledge are', 'are important', 'important for', 'for analytics']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JHMgbUXV4zGC",
        "colab_type": "code",
        "outputId": "defbba77-6664-4e73-973a-2ffca90d679a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "# Count the frequency of n-grams\n",
        "request_count = Counter(result)\n",
        "request_count"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Statistics skills': 2,\n",
              "         'analytics Statistics': 1,\n",
              "         'and domain': 1,\n",
              "         'and programming': 1,\n",
              "         'are equally': 1,\n",
              "         'are important': 1,\n",
              "         'domain knowledge': 1,\n",
              "         'equally important': 1,\n",
              "         'for analytics': 2,\n",
              "         'important for': 2,\n",
              "         'knowledge are': 1,\n",
              "         'programming skills': 1,\n",
              "         'skills and': 2,\n",
              "         'skills are': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "FCeLKKQ65le-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Convert result dictionary into 2-D Dataframe"
      ]
    },
    {
      "metadata": {
        "id": "urHvDQzx5rqE",
        "colab_type": "code",
        "outputId": "9430efd1-52ae-4704-ff8e-c02984e419ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame.from_dict(request_count, orient=\"index\")\n",
        "df\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Statistics skills</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skills and</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and programming</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>programming skills</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skills are</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>are equally</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equally important</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>important for</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for analytics</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>analytics Statistics</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and domain</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>domain knowledge</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knowledge are</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>are important</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      0\n",
              "Statistics skills     2\n",
              "skills and            2\n",
              "and programming       1\n",
              "programming skills    1\n",
              "skills are            1\n",
              "are equally           1\n",
              "equally important     1\n",
              "important for         2\n",
              "for analytics         2\n",
              "analytics Statistics  1\n",
              "and domain            1\n",
              "domain knowledge      1\n",
              "knowledge are         1\n",
              "are important         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "V3ousw_d65Pi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Rename DataFrame column name**"
      ]
    },
    {
      "metadata": {
        "id": "07B6pAqb68a3",
        "colab_type": "code",
        "outputId": "e7f6841f-c36e-476b-891a-79d9ee0f8274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "cell_type": "code",
      "source": [
        "# from dataframe, we will use rename function to rename column names\n",
        "df.rename(columns={'index':'N-grams', 0:'Frequency'})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Statistics skills</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skills and</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and programming</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>programming skills</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skills are</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>are equally</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>equally important</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>important for</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for analytics</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>analytics Statistics</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and domain</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>domain knowledge</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knowledge are</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>are important</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Frequency\n",
              "Statistics skills             2\n",
              "skills and                    2\n",
              "and programming               1\n",
              "programming skills            1\n",
              "skills are                    1\n",
              "are equally                   1\n",
              "equally important             1\n",
              "important for                 2\n",
              "for analytics                 2\n",
              "analytics Statistics          1\n",
              "and domain                    1\n",
              "domain knowledge              1\n",
              "knowledge are                 1\n",
              "are important                 1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "LTPDClp0G7yY",
        "colab_type": "code",
        "outputId": "60157368-7745-44f0-ff09-792b3b23644a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!mkdir demo\n",
        "!wget \"http://www.hackveda.in/text1.txt\"\n",
        "!wget \"http://www.hackveda.in/text2.txt\"\n",
        "!wget \"http://www.hackveda.in/text3.txt\"\n",
        "\n",
        "!mv text1.txt text2.txt text3.txt demo/\n",
        "!cd demo/\n",
        "!ls demo/\n",
        "\n",
        "for f in os.listdir(\"demo\"):\n",
        "  print(f)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-27 12:45:07--  http://www.hackveda.in/text1.txt\n",
            "Resolving www.hackveda.in (www.hackveda.in)... 192.185.129.82\n",
            "Connecting to www.hackveda.in (www.hackveda.in)|192.185.129.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142 [text/plain]\n",
            "Saving to: ‘text1.txt’\n",
            "\n",
            "\rtext1.txt             0%[                    ]       0  --.-KB/s               \rtext1.txt           100%[===================>]     142  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-27 12:45:07 (17.3 MB/s) - ‘text1.txt’ saved [142/142]\n",
            "\n",
            "--2019-02-27 12:45:07--  http://www.hackveda.in/text2.txt\n",
            "Resolving www.hackveda.in (www.hackveda.in)... 192.185.129.82\n",
            "Connecting to www.hackveda.in (www.hackveda.in)|192.185.129.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 150 [text/plain]\n",
            "Saving to: ‘text2.txt’\n",
            "\n",
            "text2.txt           100%[===================>]     150  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-27 12:45:07 (24.4 MB/s) - ‘text2.txt’ saved [150/150]\n",
            "\n",
            "--2019-02-27 12:45:08--  http://www.hackveda.in/text3.txt\n",
            "Resolving www.hackveda.in (www.hackveda.in)... 192.185.129.82\n",
            "Connecting to www.hackveda.in (www.hackveda.in)|192.185.129.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110 [text/plain]\n",
            "Saving to: ‘text3.txt’\n",
            "\n",
            "text3.txt           100%[===================>]     110  --.-KB/s    in 0s      \n",
            "\n",
            "2019-02-27 12:45:08 (16.8 MB/s) - ‘text3.txt’ saved [110/110]\n",
            "\n",
            "text1.txt  text2.txt  text3.txt\n",
            "text1.txt\n",
            "text3.txt\n",
            "text2.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VBqCP12r8zD3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Day 12**\n",
        "-------------\n",
        "\n",
        "\n",
        "**Bag of Words**\n",
        "-----------------------------\n",
        "\n",
        "Bag of Words =  Counting the occurance of words in a document\n",
        "\n",
        "No importance of grammer and order of words\n",
        "\n",
        "\n",
        "#**Term Document Matrix**\n",
        "---------------------------------\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EzzPJKBK-HQv",
        "colab_type": "code",
        "outputId": "df3db475-5352-4a56-b19d-79829b29adb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#Term Document Matrix\n",
        "\n",
        "import pandas as pd\n",
        "#sklearn libraries feature extraction is used to extract text tokens\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "# Function to create a dictionary with key as file, and values as names\n",
        "def CorpusFromDir(dir_path):\n",
        "  result = dict(docs = [open(os.path.join(dir_path, f)).read() for f in \n",
        "  os.listdir(dir_path)], ColNames = map(lambda x: x, os.listdir(dir_path)))\n",
        "  return result\n",
        "\n",
        "\n",
        "docs = CorpusFromDir(\"demo\")\n",
        "docs\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ColNames': <map at 0x7f84951a20b8>,\n",
              " 'docs': ['\\ufeffThe air strike on terror camps in Pakistan is a positive for the markets as it illustrates a \"decisiveness\" in foreign policy and increases',\n",
              "  '\\ufeffThe U.S. military said on Monday that a recent air strike in central Somalia killed 35 al Shabaab fighters.',\n",
              "  '\\ufeffAfter India carried out pre-dawn \"non-military, pre-emptive air strikes\" across the Line of Control on Tuesday to target the biggest camp of terror']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "WoyM-nuq_xlr",
        "colab_type": "code",
        "outputId": "d1093a07-c734-41fa-d262-230dd1140b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# CountVectorizer = Convert a collection of text documents to a matrix of token counts\n",
        "#CountVectorizer()\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "doc_vec = vectorizer.fit_transform(docs.get('docs'))\n",
        "doc_vec"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x50 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 60 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "eLUB_8Q8IK6h",
        "colab_type": "code",
        "outputId": "e86c1477-0a61-43cb-922e-dda58d5a497c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        }
      },
      "cell_type": "code",
      "source": [
        "# Create a DataFrame\n",
        "df = pd.DataFrame(doc_vec.toarray().transpose(), index=vectorizer.get_feature_names())\n",
        "df\n",
        "\n",
        "# Display the file names\n",
        "df.columns = docs.get('ColNames')\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text1.txt</th>\n",
              "      <th>text3.txt</th>\n",
              "      <th>text2.txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>across</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>air</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>as</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>biggest</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>camp</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>camps</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carried</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>central</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>control</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dawn</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decisiveness</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emptive</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fighters</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>illustrates</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>increases</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>india</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>killed</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>markets</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>military</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monday</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>on</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>out</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pakistan</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pre</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recent</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>said</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shabaab</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>somalia</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>strike</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>strikes</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>terror</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>that</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tuesday</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              text1.txt  text3.txt  text2.txt\n",
              "35                    0          1          0\n",
              "across                0          0          1\n",
              "after                 0          0          1\n",
              "air                   1          1          1\n",
              "al                    0          1          0\n",
              "and                   1          0          0\n",
              "as                    1          0          0\n",
              "biggest               0          0          1\n",
              "camp                  0          0          1\n",
              "camps                 1          0          0\n",
              "carried               0          0          1\n",
              "central               0          1          0\n",
              "control               0          0          1\n",
              "dawn                  0          0          1\n",
              "decisiveness          1          0          0\n",
              "emptive               0          0          1\n",
              "fighters              0          1          0\n",
              "for                   1          0          0\n",
              "foreign               1          0          0\n",
              "illustrates           1          0          0\n",
              "in                    2          1          0\n",
              "increases             1          0          0\n",
              "india                 0          0          1\n",
              "is                    1          0          0\n",
              "it                    1          0          0\n",
              "killed                0          1          0\n",
              "line                  0          0          1\n",
              "markets               1          0          0\n",
              "military              0          1          1\n",
              "monday                0          1          0\n",
              "non                   0          0          1\n",
              "of                    0          0          2\n",
              "on                    1          1          1\n",
              "out                   0          0          1\n",
              "pakistan              1          0          0\n",
              "policy                1          0          0\n",
              "positive              1          0          0\n",
              "pre                   0          0          2\n",
              "recent                0          1          0\n",
              "said                  0          1          0\n",
              "shabaab               0          1          0\n",
              "somalia               0          1          0\n",
              "strike                1          1          0\n",
              "strikes               0          0          1\n",
              "target                0          0          1\n",
              "terror                1          0          1\n",
              "that                  0          1          0\n",
              "the                   2          1          2\n",
              "to                    0          0          1\n",
              "tuesday               0          0          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "u7RIMlKy_z2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5cedfb2-7fa2-4757-b88d-33b1b13c5fd4"
      },
      "cell_type": "code",
      "source": [
        "!ls demo/"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text1.txt  text2.txt  text3.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vbz3iNfHCDFe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Day 13:\n",
        "\n",
        "# Term Frequency / Inverse Document Frequency (TF*IDF)\n",
        "#(using Vectorizer)\n",
        "Term Frequency =  (Number of times term appears in a document / Total number of terms in the document)\n",
        "Document Frequency = (Number od documents containing a given term/the size of the collection of the documents)\n",
        "Inverse Document Frequency (IDF) = (Total number of document)/Number of documents"
      ]
    },
    {
      "metadata": {
        "id": "I02cTkBmANwR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac2efa01-f0f4-4718-c67d-147aa15aced8"
      },
      "cell_type": "code",
      "source": [
        "# Term Frequency - Inverse Document Frequency (using Vectorizer)\n",
        "# Term Frequency =  (Number of times term appears in a document / Total number of terms in the document)\n",
        "# Document Frequency = (Number od documents containing a given term/the size of the collection of the documents)\n",
        "\n",
        "'''The TF (term frequency) of a word is the frequency of a word (i.e. number of times it appears) in a document. When you know it, you're able to see if you're using a term too much or too little. The IDF (inverse document frequency) of a word is the measure of how significant that term is in the whole corpus\n",
        "\n",
        "https://www.elephate.com/blog/what-is-tf-idf/\n",
        "\n",
        "TF*IDF is used by search engines to better understand content which is undervalued. \n",
        "For example, if you’d want to search a term “Coke” on Google, this is how Google can figure out if a page titled “COKE” is about:\n",
        "\n",
        "a) Coca-Cola.\n",
        "b) Cocaine.\n",
        "c) A solid, carbon-rich residue derived from the distillation of crude oil.\n",
        "d) A county in Texas.\n",
        "\n",
        "'''\n",
        "\n",
        "# Inverse Document Frequency (IDF) = (Total number of document)/Number of documents with a given term)\n",
        "\n",
        "# Let's say we have total # of words in a document is 100, and ML appeared only 3\n",
        "# Doc = 100 (ML = 3)\n",
        "#TF = 3/100 = 0.03\n",
        "\n",
        "total_number_words = 100\n",
        "number_ml_words = 70\n",
        "term_freq = number_ml_words/ total_number_words\n",
        "print(term_freq)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HrEqPFOrEhje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0b8db1cf-ac96-4923-f610-4fbfc7045627"
      },
      "cell_type": "code",
      "source": [
        "# Calculation of document frequency on any search\n",
        "number_of_docs_containing_given_term = 6\n",
        "total_number_docs = 10\n",
        "\n",
        "#calculate the document frequency\n",
        "doc_freq = number_of_docs_containing_given_term/ total_number_docs\n",
        "print(doc_freq)\n",
        "\n",
        "'''Once we get DF, now we have to normalize the document-frequency so as to have\n",
        "the values represented on same scale\n",
        "\n",
        "Now, we are going to normalize using log() function, if we get negative value, we need to\n",
        "utilize the inverse of Document Frequncy (IDF) to avoid negative outcome of normalization\n",
        "\n",
        "IDF = log(total number of documents / number of docs with given term)\n",
        "\n",
        "TF-IDF (Term Frequency * Inverse Document Frequency) = (0-1)\n",
        "The value near to 1 will be more relevant e.g., 0.8 is far relevent than 0.3'''\n",
        "\n",
        "\n",
        "\n",
        "print(term_freq * doc_freq)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6\n",
            "0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBkAjsmvHgEg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!cat demo/text1.txt\n",
        "#!cat demo/text2.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLt_-l76H8Yu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ee90f453-5d25-44b4-9805-b4842b4e1c8d"
      },
      "cell_type": "code",
      "source": [
        "# Now Python solution for TF/IDF\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# read each and every documents, out of the doc it will extract all contents, then will\n",
        "# calculate document frequency, IDF, and normalize\n",
        "vectorizer  = TfidfVectorizer()\n",
        "\n",
        "# call Corpus from dir function to read content from current working directory\n",
        "docs = CorpusFromDir(\"/content/demo/\")\n",
        "docs\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ColNames': <map at 0x7f849519e8d0>,\n",
              " 'docs': ['\\ufeffThe air strike on terror camps in Pakistan is a positive for the markets as it illustrates a \"decisiveness\" in foreign policy and increases',\n",
              "  '\\ufeffThe U.S. military said on Monday that a recent air strike in central Somalia killed 35 al Shabaab fighters.',\n",
              "  '\\ufeffAfter India carried out pre-dawn \"non-military, pre-emptive air strikes\" across the Line of Control on Tuesday to target the biggest camp of terror']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-C6JmKMKOYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1547
        },
        "outputId": "34957f90-b745-49b6-a64d-31ea3298e2dd"
      },
      "cell_type": "code",
      "source": [
        "# Vectorizer will learn the vocabulary and idf, return term-document matrix.\n",
        "doc_term_matrix = vectorizer.fit_transform(docs.get('docs'))\n",
        "#doc_term_matrix.toarray()\n",
        "term_doc_matrix = doc_term_matrix.toarray().transpose()\n",
        "\n",
        "# columns are documents and terms are rows now after transpose, and the values are IDF\n",
        "\n",
        "\n",
        "# check the total number of terms\n",
        "terms = vectorizer.get_feature_names()\n",
        "\n",
        "\n",
        "#Lets create a dataframe\n",
        "df = pd.DataFrame(term_doc_matrix, index=terms)\n",
        "#df\n",
        "\n",
        "#Lets tag the column names \n",
        "\n",
        "df.columns  = docs.get('ColNames')\n",
        "df"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text1.txt</th>\n",
              "      <th>text3.txt</th>\n",
              "      <th>text2.txt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>across</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>after</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>air</th>\n",
              "      <td>0.133531</td>\n",
              "      <td>0.159094</td>\n",
              "      <td>0.113142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>al</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>as</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>biggest</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>camp</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>camps</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>carried</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>central</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>control</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dawn</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>decisiveness</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emptive</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fighters</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>illustrates</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>0.343892</td>\n",
              "      <td>0.204863</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>increases</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>india</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>killed</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>markets</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>military</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.204863</td>\n",
              "      <td>0.145691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>monday</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.383132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>on</th>\n",
              "      <td>0.133531</td>\n",
              "      <td>0.159094</td>\n",
              "      <td>0.113142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>out</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pakistan</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>policy</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>positive</th>\n",
              "      <td>0.226088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pre</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.383132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recent</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>said</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shabaab</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>somalia</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>strike</th>\n",
              "      <td>0.171946</td>\n",
              "      <td>0.204863</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>strikes</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>terror</th>\n",
              "      <td>0.171946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>that</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269370</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>0.267063</td>\n",
              "      <td>0.159094</td>\n",
              "      <td>0.226284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tuesday</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191566</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              text1.txt  text3.txt  text2.txt\n",
              "35             0.000000   0.269370   0.000000\n",
              "across         0.000000   0.000000   0.191566\n",
              "after          0.000000   0.000000   0.191566\n",
              "air            0.133531   0.159094   0.113142\n",
              "al             0.000000   0.269370   0.000000\n",
              "and            0.226088   0.000000   0.000000\n",
              "as             0.226088   0.000000   0.000000\n",
              "biggest        0.000000   0.000000   0.191566\n",
              "camp           0.000000   0.000000   0.191566\n",
              "camps          0.226088   0.000000   0.000000\n",
              "carried        0.000000   0.000000   0.191566\n",
              "central        0.000000   0.269370   0.000000\n",
              "control        0.000000   0.000000   0.191566\n",
              "dawn           0.000000   0.000000   0.191566\n",
              "decisiveness   0.226088   0.000000   0.000000\n",
              "emptive        0.000000   0.000000   0.191566\n",
              "fighters       0.000000   0.269370   0.000000\n",
              "for            0.226088   0.000000   0.000000\n",
              "foreign        0.226088   0.000000   0.000000\n",
              "illustrates    0.226088   0.000000   0.000000\n",
              "in             0.343892   0.204863   0.000000\n",
              "increases      0.226088   0.000000   0.000000\n",
              "india          0.000000   0.000000   0.191566\n",
              "is             0.226088   0.000000   0.000000\n",
              "it             0.226088   0.000000   0.000000\n",
              "killed         0.000000   0.269370   0.000000\n",
              "line           0.000000   0.000000   0.191566\n",
              "markets        0.226088   0.000000   0.000000\n",
              "military       0.000000   0.204863   0.145691\n",
              "monday         0.000000   0.269370   0.000000\n",
              "non            0.000000   0.000000   0.191566\n",
              "of             0.000000   0.000000   0.383132\n",
              "on             0.133531   0.159094   0.113142\n",
              "out            0.000000   0.000000   0.191566\n",
              "pakistan       0.226088   0.000000   0.000000\n",
              "policy         0.226088   0.000000   0.000000\n",
              "positive       0.226088   0.000000   0.000000\n",
              "pre            0.000000   0.000000   0.383132\n",
              "recent         0.000000   0.269370   0.000000\n",
              "said           0.000000   0.269370   0.000000\n",
              "shabaab        0.000000   0.269370   0.000000\n",
              "somalia        0.000000   0.269370   0.000000\n",
              "strike         0.171946   0.204863   0.000000\n",
              "strikes        0.000000   0.000000   0.191566\n",
              "target         0.000000   0.000000   0.191566\n",
              "terror         0.171946   0.000000   0.145691\n",
              "that           0.000000   0.269370   0.000000\n",
              "the            0.267063   0.159094   0.226284\n",
              "to             0.000000   0.000000   0.191566\n",
              "tuesday        0.000000   0.000000   0.191566"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}