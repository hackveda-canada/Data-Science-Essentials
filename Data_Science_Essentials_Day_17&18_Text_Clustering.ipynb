{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science Essentials_Day_17&18: Text Clustering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hackveda-canada/Data-Science-Essentials/blob/master/Data_Science_Essentials_Day_17%2618_Text_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Nnxw0G-vD9ZG",
        "colab_type": "code",
        "outputId": "244caeba-c436-4d5b-e5ea-dc436941107c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Inbuilt function to calculate cosine similarity using Sklearn library\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import pandas as pd\n",
        "dict1 = {'doc1.txt':[10], 'doc2.txt':[3]}\n",
        "df = pd.DataFrame(dict1)\n",
        "df\n",
        "\n",
        "cosine_similarity(df[['doc1.txt']], df[['doc2.txt']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "IkFJXPBnHBEz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Text Clustering\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
        "newsgroups_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oSFthL1xIsuD",
        "colab_type": "code",
        "outputId": "1edb3450-ca04-4c65-c3c1-b35ddd876f01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "newsgroups_train.target_names"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "tM621QjUI_cU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'rec.motorcycles']\n",
        "dataset = fetch_20newsgroups(subset=\"all\", categories=categories, shuffle=True, random_state=5)\n",
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BXB-Y71tKcta",
        "colab_type": "code",
        "outputId": "e4a42e96-3a11-4f8d-d0fe-33cfdbbdfd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Calculate size of data and target\n",
        "print(\"%d documents\" % len(dataset.data))\n",
        "print(\"%d categories\" % len(dataset.target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3753 documents\n",
            "4 categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3-topIWVLiL-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "\n",
        "print(\"Non Vectorized Data \\n\")\n",
        "dataset.data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5lBfwYdmMg8-",
        "colab_type": "code",
        "outputId": "6b591e03-c5b6-4304-c1a5-1a8141e39e11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(dataset.data)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3753, 83000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "MyzvyG7HNBfs",
        "colab_type": "code",
        "outputId": "da33abdc-01a7-452a-bdd5-28405765d64a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"%d documents, %d features\" % X.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3753 documents, 83000 features\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R8o_vAXsNOIF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X.toarray().transpose(), index=vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YMyYERaZOdoD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SVD of a matrix ( m rows * n columns ) Term Document Matrix\n",
        "# Product of \n",
        "# r = rank of the matrix\n",
        "# a.) Column orthonormal = m * r \n",
        "# b.) Diagonal = r * r\n",
        "# c.) Column orthonormal = r * n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7-jlLhrRx4S",
        "colab_type": "code",
        "outputId": "62c8398e-694c-400e-f4e4-8ebf382ff629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# (text clustering) Latent semantic analysis using SVD\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Shape of original matrix\n",
        "X.shape\n",
        "\n",
        "# print the documents and dimensions\n",
        "print(\"%d documents, %d dimensions\" % X.shape)\n",
        "\n",
        "# To perform Latent semantic analysis through SVD we have to decompose original matrix\n",
        "svd = TruncatedSVD(2000)\n",
        "\n",
        "# Create LSA using SVD\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "\n",
        "# Transform X matrix into lsa (svd) matrix \n",
        "X = lsa.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3753 documents, 83000 dimensions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-ibs-XzlYDxH",
        "colab_type": "code",
        "outputId": "bf724fda-abb5-4b42-9327-c9c98385c3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Check Shape of the matrix\n",
        "print(\"%d documents, %d dimensions\" % X.shape)\n",
        "\n",
        "# Check the explained variance after decomposition\n",
        "evr = svd.explained_variance_ratio_.sum()\n",
        "print(\"Dimensions reduced to \", evr * 100, \" %\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3753 documents, 2000 dimensions\n",
            "Dimensions reduced to  87.90560728992392  %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jARBMmzFa6bz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Text Clustering using Kmeans and SVD Data\n",
        "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "kmeans = KMeans(n_clusters=4, max_iter=100, n_init=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gxaHcCWtc1vb",
        "colab_type": "code",
        "outputId": "aab6a357-7e64-4cf0-de43-79a00216d6dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "# Run Kmeans in batch mode. Useful for large datasets\n",
        "kmeans = MiniBatchKMeans(n_clusters=4, n_init=1, batch_size=1000)\n",
        "kmeans.fit(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
              "        init_size=None, max_iter=100, max_no_improvement=10, n_clusters=4,\n",
              "        n_init=1, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
              "        verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    }
  ]
}